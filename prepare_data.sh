#!/usr/bin/env bash

set -euo pipefail

data_root=data
data_sets="cerf_train_tr cerf_train_cv"
model_name="gigaspeech"
text="text"
dumpdir=dump
verbose=0
stage=0
CUDA=
stop_stage=
s2t=false
long_decode_mode=true
tag="20220428_prompt"
savejson=data.new.json
ctc_aligner=true

. utils/parse_options.sh


. ./path.sh
. ./cmd.sh

if [ ${stage} -le 0 ] && [ ${stop_stage} -ge 0 ]; then
    for data_set in $data_sets; do
        CUDA_VISIBLE_DEVICES=${CUDA} python local.apl.v1/stt/prepare_feats.py --data_dir $data_root/$data_set \
            --model_name $model_name \
            --text_path $data_root/$data_set/$text \
            --tag $tag \
            --ngpu 1 \
            --s2t $s2t \
            --ctc_aligner $ctc_aligner \
            --long_decode_mode $long_decode_mode \
            --dict data/local/dict/lexicon.txt # We can use the dicts generated by Kaldi toolkit or ESPNet toolkit here
            # --dict data/lang_1char/cefr_train_tr_units.txt
    done
fi

if [ ${stage} -le 1 ]&& [ ${stop_stage} -ge 1 ]; then
    for data_set in $data_sets; do
        json=$dumpdir/$data_set/deltafalse/data.json
        appd=$data_root/$data_set/${model_name}_${tag}/all.json
        # @https://espnet.github.io/espnet/apis/utils_py.html#addjson-py
        addjson.py --verbose ${verbose} -i true \
            ${json} ${appd} > $dumpdir/$data_set/deltafalse/${savejson}
    done
fi

# if [ $stage -le 2 ]; then
#     for data_set in $data_sets; do
#         i_json=dump/$data_set/deltafalse/data.tmp.json
#         o_json=dump/$data_set/deltafalse/data.new.json
#         mv ${o_json} ${i_json}
#         python local/stt/remove_short_utterances_by_text.py --input_json ${i_json} \
#             --output_json ${o_json} \
#             --filter_len 5
#         rm ${i_json}
#     done
# fi

# if [ $stage -le 3 ]; then
#     for data_set in $data_sets; do
#         i_json=dump/$data_set/deltafalse/data.tmp.json
#         o_json=dump/$data_set/deltafalse/data.new.json
#         # mv ${o_json} ${i_json}
#         python local/stt/fix_ctm_long.py --input_json ${i_json} \
#             --output_json ${o_json}
#         # rm ${i_json}
#     done
# fi

# if [ $stage -le 4 ]; then
#     for data_set in $data_sets; do
#         i_json=dump/$data_set/deltafalse/data.tmp.json
#         o_json=dump/$data_set/deltafalse/data.new.json
#         mv ${o_json} ${i_json}
#         python local/stt/fix_ctm_long.py --input_json ${i_json} \
#             --output_json ${o_json}
#         rm ${i_json}
#     done
# fi